{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fea1f40d",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e374e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import polars as pl\n",
    "import gensim.downloader as gsdl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea7fc75",
   "metadata": {},
   "source": [
    "# 2. Feature engineering\n",
    "\n",
    "- First let load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec8be60",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"/home/leminhohoho/repos/movie-lens/db/letterboxd.db\")\n",
    "\n",
    "activities = pl.read_database(\"SELECT * FROM users_and_movies\", connection=conn)\n",
    "\n",
    "movies = pl.read_database(\"SELECT * FROM movies\", connection=conn)\n",
    "\n",
    "genres_and_movies = pl.read_database(\"SELECT movie_id, name FROM genres_and_movies JOIN genres ON genres.id = genre_id\", connection=conn)\n",
    "genres_per_movie = (\n",
    "    genres_and_movies\n",
    "    .group_by(\"movie_id\")\n",
    "    .agg(pl.col(\"name\").str.to_lowercase().alias(\"genres_name\"))\n",
    ")\n",
    "\n",
    "languages_and_movies = pl.read_database(\"SELECT movie_id, language FROM languages_and_movies\", connection=conn)\n",
    "languages_per_movie = (\n",
    "    languages_and_movies\n",
    "    .group_by(\"movie_id\")\n",
    "    .agg(pl.col(\"language\").str.to_lowercase().alias(\"languages_name\"))\n",
    ")\n",
    "\n",
    "releases = pl.read_database(\"SELECT movie_id, date FROM releases GROUP BY movie_id\", connection=conn)\n",
    "\n",
    "with pl.Config(tbl_cols=-1):\n",
    "    print(activities)\n",
    "    print(movies)\n",
    "    print(genres_per_movie)\n",
    "    print(languages_per_movie)\n",
    "    print(releases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5256d7",
   "metadata": {},
   "source": [
    "## 2.1 Encoding features\n",
    "\n",
    "- Since genres & languages are not fixed, it would be impossible to use them as the vocabulary for the model, instead we will vectorized them using pre trained embedding models\n",
    "- First let load the encoder and the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5191a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = gsdl.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cb3d89",
   "metadata": {},
   "source": [
    "- Since languages have varations (e.g `greek (modern)`), which if passed without modifcation to the embedding model will cause error since they are not presented, we will create a perform string extraction to make the valid for embedding before doing so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a891ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def embed_languages(languages):\n",
    "    vecs = []\n",
    "\n",
    "    for lang in languages:\n",
    "          try:\n",
    "              vecs.append(word_vecs.get_vector(lang))\n",
    "          except KeyError:\n",
    "              vecs.append(word_vecs.get_mean_vector(re.split(r'[^a-zA-Z0-9]+', lang)))\n",
    "\n",
    "    return np.mean(vecs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552d33ce",
   "metadata": {},
   "source": [
    "- Now we will embed the `genres` and `languages`, also we will convert date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0187adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "enc_movies = movies.join(\n",
    "        genres_per_movie, how=\"left\", left_on=\"id\", right_on=\"movie_id\"\n",
    "    ).join(\n",
    "        languages_per_movie, how=\"left\", left_on=\"id\", right_on=\"movie_id\"\n",
    "    ).join(\n",
    "        releases, how=\"left\", left_on=\"id\", right_on=\"movie_id\"\n",
    "    ).with_columns(\n",
    "        pl.col(\"genres_name\")\n",
    "            .map_elements(word_vecs.get_mean_vector)\n",
    "            .map_elements(lambda x: x.tolist(), return_dtype=pl.List(pl.Float32))\n",
    "            .alias(\"embd_genres\"),\n",
    "        pl.col(\"languages_name\")\n",
    "            .map_elements(embed_languages)\n",
    "            .map_elements(lambda x: x.tolist(), return_dtype=pl.List(pl.Float32))\n",
    "            .alias(\"embd_languages\"),\n",
    "        # pl.when(pl.col(\"desc\").is_not_null())\n",
    "        #     .then(pl.col(\"desc\").str.to_lowercase().map_elements(enc.encode, return_dtype=pl.List(pl.Int64)))\n",
    "        #     .otherwise(pl.lit([])).alias(\"enc_movie_desc\"),\n",
    "        # pl.when(pl.col(\"name\").str.to_lowercase().is_not_null())\n",
    "        #     .then(pl.col(\"name\").map_elements(enc.encode, return_dtype=pl.List(pl.Int64)))\n",
    "        #     .otherwise(pl.lit([])).alias(\"enc_movie_name\"),\n",
    "        (pl.col(\"date\")\n",
    "                .str.strptime(pl.Datetime, format=\"%d %b %Y\", strict=True)\n",
    "                .dt.replace_time_zone(\"UTC\") \n",
    "                .dt.timestamp() / 10**16)            \n",
    "                .alias(\"enc_release_date\"),\n",
    "        pl.col(\"duration\").log(base=10).tanh()\n",
    "    ).drop([\n",
    "        \"url\", \"poster_url\", \"backdrop_url\", \"trailer_url\", \"date\", \"genres_name\", \"languages_name\", \"desc\",\n",
    "    ]).filter(\n",
    "        pl.col(\"embd_genres\").is_not_null()\n",
    "    )\n",
    "\n",
    "enc_movies = enc_movies.with_columns(\n",
    "    pl.col(\"duration\").fill_null(pl.col(\"duration\").mean()),\n",
    "    pl.col(\"duration\").is_null().alias(\"duration_missing\"),\n",
    "    pl.col(\"embd_languages\").fill_null(pl.lit(word_vecs.get_vector(\"unknown\").tolist())),\n",
    "    pl.col(\"enc_release_date\").fill_null(pl.col(\"enc_release_date\").mean()),\n",
    "    pl.col(\"enc_release_date\").is_null().alias(\"releases_date_missing\")\n",
    ")\n",
    "\n",
    "print(enc_movies)\n",
    "print(enc_movies.drop(\"name\").describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01898b41",
   "metadata": {},
   "source": [
    "- Now we will encode user activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a36fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_activities = activities.join(\n",
    "    enc_movies, left_on=\"movie_id\", right_on=\"id\", how=\"semi\"\n",
    ").with_columns(\n",
    "    # pl.when(pl.col(\"review\").is_not_null())\n",
    "    #   .then(pl.col(\"review\").map_elements(enc.encode, return_dtype=pl.List(pl.Int64)))\n",
    "    #   .otherwise(pl.lit([])).alias(\"enc_review\"),\n",
    "    ((pl.col(\"date\").str.slice(0, 18) + \"Z\")\n",
    "        .str.strptime(pl.Datetime, format=\"%Y-%m-%dT%H:%M:%SZ\", strict=False)\n",
    "        .dt.replace_time_zone(\"UTC\") \n",
    "        .dt.timestamp() / 10**16)\n",
    "        .alias(\"enc_time\")\n",
    "    \n",
    ").drop([\"date\", \"review\"])\n",
    "\n",
    "enc_activities = enc_activities.with_columns(\n",
    "    pl.col(\"rating\").fill_null(pl.col(\"rating\").mean()) / 5,\n",
    "    pl.col(\"rating\").is_null().alias(\"rating_missing\"),\n",
    "    pl.col(\"enc_time\").fill_null(pl.col(\"enc_time\").mean()),\n",
    "    pl.col(\"enc_time\").is_null().alias(\"time_missing\")\n",
    ")\n",
    "\n",
    "\n",
    "with pl.Config(tbl_cols=-1):\n",
    "    print(enc_activities)\n",
    "    print(enc_activities.drop([\"movie_id\", \"user_id\"]).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f042175",
   "metadata": {},
   "source": [
    "# 3. Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b4bf3f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "enc_movies.write_parquet(\"/home/leminhohoho/repos/movie-lens/ml/data/encoded_movies.parquet\")\n",
    "enc_activities.write_parquet(\"/home/leminhohoho/repos/movie-lens/ml/data/encoded_activities.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd3a9e0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
